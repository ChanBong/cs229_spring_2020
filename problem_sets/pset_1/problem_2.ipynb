{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "democratic-trail",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "2. **(a) Consider the poisson distribution parametrized by $\\lambda$**\n",
    "$$\n",
    "p(y; Y) = \\frac{e^{-\\lambda} \\lambda^y}{y!}\n",
    "$$\n",
    "Show that poisson distribution is in the exponential family"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-immune",
   "metadata": {},
   "source": [
    "##### Sol:\n",
    "Exponential families have the general form of \n",
    "$$\n",
    "p(y;\\eta) = b(y)\\exp{(\\eta^T T(y) - a(\\eta))}\n",
    "$$\n",
    "By comparing with the poisson's distribution, \n",
    "- $b(y) = \\frac{1}{y!}$\n",
    "- $\\eta = \\log \\lambda$\n",
    "- $T(y) = y$\n",
    "- $a(\\eta) = e^{\\eta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-equality",
   "metadata": {},
   "source": [
    "2. (b) **Find the cannonical response function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-framework",
   "metadata": {},
   "source": [
    "The canonical response function for the Poisson distribution is given by:\n",
    "$$\n",
    "g(\\eta) = E(y;\\eta) = \\frac{\\partial{a(\\eta)}}{\\partial \\eta} = \\lambda = e^{\\eta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-lancaster",
   "metadata": {},
   "source": [
    "2. (c) **For a training set let, the log-likelihood of a training example $(x^i, y^i)$ is given by $\\log p(y^i|x^i;\\theta)$. derive the stochastic gradient descent update rule**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-cleveland",
   "metadata": {},
   "source": [
    "To get the stochastic gradient descent update rule, we have to compute the partial derivative of the log-likelihood with respect to parameter $\\theta_j$. Also consider $\\eta = \\theta^T x^i$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} \\log p(y^i|x^i;\\theta) &= \\frac{\\partial}{\\partial \\theta_j} ((\\theta^T x^i)^T y^i - e^{\\theta^T x^i}) \\\\\n",
    "&= (y^i-e^{\\theta^T x^i})x_j^i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "To make appropriate use of this update rule we have to introduce a hyperparameter, $\\alpha$, learning rate\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha.(y^i-e^{\\theta^T x^i})x_j^i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-indiana",
   "metadata": {},
   "source": [
    "2. (d) **Show for any memeber of the exponential family stochastic grdiant ascent on log-liklihood results in the same update rule**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-finding",
   "metadata": {},
   "source": [
    "Considering the ususal form of exponential family\n",
    "$$\n",
    "p(y;\\eta) = b(y)\\exp{(\\eta^T T(y) - a(\\eta))}\n",
    "$$\n",
    "\n",
    "we compute the partial derivative of the log-likelihood with respect to parameter $\\theta_j$. Also consider $\\eta = \\theta^T x^i$ and $T(y) = y$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} \\log p(y^i|x^i;\\theta) &= \\frac{\\partial}{\\partial \\theta_j} (b(y) + (\\eta^T y - a(\\eta) \\\\\n",
    "&= (y^i x_j^i - \\frac{\\partial}{\\partial \\theta_j} a(\\theta^T x^i)) \\\\\n",
    "&= (y^i - h_\\theta(x))x_j^i  \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "(Reacall that $\\frac{\\partial}{\\partial \\eta} a(\\eta)) = h_\\theta(x))$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
